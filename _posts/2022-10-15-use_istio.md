---
layout: post
title: "[Infra] Minikube에서 Istio 사용기"
date: 2022-10-14
desc: "[Infra] Minikube에서 Istio 사용기"
keywords: "son,blog,infra,docker,minikube,kubectl,kubernetes,istio,kiali"
categories: [Infra]
tags: [son,blog,infra,docker,minikube,kubectl,kubernetes,istio,kiali]
icon: icon-html
---

[이전 포스팅](http://crisis513.github.io/infra/2021/10/13/install.istio.html "이전 포스팅")과 이어지는 내용으로, [개발 환경](http://crisis513.github.io/infra/2021/10/13/install_minikube.html#list1_2 "개발 환경")은 해당 포스팅을 참고 바란다.

---

## 목차

[1. Istio 사용기](#list1)

[&nbsp;&nbsp; 1.1. addons 배포](#list1_1)

[&nbsp;&nbsp; 1.2. helloworld 예제 앱 배포](#list1_2)

[&nbsp;&nbsp; 1.3. Kiali dashboard 사용](#list1_3)

---

## <span style="color:purple">**1. Istio 사용기**</span> <a name="list1"></a>

<br>

### 1.1. addons 배포 <a name="list1_1"></a>

  이전 포스팅과 같이 정상적으로 istio 설치되었다면 이번 포스팅에서는 istio 폴더에서 샘플로 제공되는 addons에 존재하는 모든 매니페스트를 쿠버네티스에 배포해보겠다.

  ```bash
  son@son-localhost ~ $ ls istio-1.15.2/samples/addons
  extras  grafana.yaml  jaeger.yaml  kiali.yaml  prometheus.yaml  README.md
  son@son-localhost ~ $ kubectl apply -f istio-1.15.2/samples/addons
  serviceaccount/grafana created
  configmap/grafana created
  service/grafana created
  deployment.apps/grafana created
  configmap/istio-grafana-dashboards created
  configmap/istio-services-grafana-dashboards created
  deployment.apps/jaeger created
  service/tracing created
  service/zipkin created
  service/jaeger-collector created
  serviceaccount/kiali created
  configmap/kiali created
  clusterrole.rbac.authorization.k8s.io/kiali-viewer created
  clusterrole.rbac.authorization.k8s.io/kiali created
  clusterrolebinding.rbac.authorization.k8s.io/kiali created
  role.rbac.authorization.k8s.io/kiali-controlplane created
  rolebinding.rbac.authorization.k8s.io/kiali-controlplane created
  service/kiali created
  deployment.apps/kiali created
  serviceaccount/prometheus created
  configmap/prometheus created
  clusterrole.rbac.authorization.k8s.io/prometheus created
  clusterrolebinding.rbac.authorization.k8s.io/prometheus created
  service/prometheus created
  deployment.apps/prometheus created

  son@son-localhost ~ $ kubectl get all -n istio-system
  NAME                                        READY   STATUS    RESTARTS   AGE
  pod/grafana-56bdf8bf85-2ccqf                1/1     Running   0          2m58s
  pod/istio-egressgateway-fffc799cf-kd26t     1/1     Running   0          9m35s
  pod/istio-ingressgateway-7d68764b55-ckkc5   1/1     Running   0          9m35s
  pod/istiod-5456fd558d-x6jpf                 1/1     Running   0          10m
  pod/jaeger-c4fdf6674-gz6fg                  1/1     Running   0          2m58s
  pod/kiali-5ff49b9f69-tlbrj                  1/1     Running   0          2m58s
  pod/prometheus-85949fddb-gwqkl              2/2     Running   0          2m57s

  NAME                           TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                                                                      AGE
  service/grafana                ClusterIP      10.104.101.157   <none>          3000/TCP                                                                     2m58s
  service/istio-egressgateway    ClusterIP      10.105.237.74    <none>          80/TCP,443/TCP                                                               18m
  service/istio-ingressgateway   LoadBalancer   10.97.166.77     192.168.49.100  15021:32414/TCP,80:30295/TCP,443:30180/TCP,31400:30731/TCP,15443:30050/TCP   18m
  service/istiod                 ClusterIP      10.109.182.176   <none>          15010/TCP,15012/TCP,443/TCP,15014/TCP                                        18m
  service/jaeger-collector       ClusterIP      10.104.197.76    <none>          14268/TCP,14250/TCP,9411/TCP                                                 2m58s
  service/kiali                  ClusterIP      10.109.226.241   <none>          20001/TCP,9090/TCP                                                           2m58s
  service/prometheus             ClusterIP      10.100.195.182   <none>          9090/TCP                                                                     2m58s
  service/tracing                ClusterIP      10.100.65.84     <none>          80/TCP,16685/TCP                                                             2m58s
  service/zipkin                 ClusterIP      10.108.103.68    <none>          9411/TCP                                                                     2m58s

  NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE
  deployment.apps/grafana                1/1     1            1           2m58s
  deployment.apps/istio-egressgateway    1/1     1            1           18m
  deployment.apps/istio-ingressgateway   1/1     1            1           18m
  deployment.apps/istiod                 1/1     1            1           18m
  deployment.apps/jaeger                 1/1     1            1           2m58s
  deployment.apps/kiali                  1/1     1            1           2m58s
  deployment.apps/prometheus             1/1     1            1           2m57s

  NAME                                              DESIRED   CURRENT   READY   AGE
  replicaset.apps/grafana-56bdf8bf85                1         1         1       2m58s
  replicaset.apps/istio-egressgateway-fffc799cf     1         1         1       9m35s
  replicaset.apps/istio-ingressgateway-7d68764b55   1         1         1       9m35s
  replicaset.apps/istiod-5456fd558d                 1         1         1       10m
  replicaset.apps/jaeger-c4fdf6674                  1         1         1       2m58s
  replicaset.apps/kiali-5ff49b9f69                  1         1         1       2m58s
  replicaset.apps/prometheus-85949fddb              1         1         1       2m57s
  ```

  istio 디렉토리에서 samples/addons 경로에는 istio와 통합되는 다양한 addon의 샘플이 포함되어 있다. istio의 일부가 아닌 서드파티 형태의 툴이지만 istio의 기능을 최대한 활용할 수 있기 때문에 필수로 사용되고 있다.

  각각의 툴에 대해 간단하게 정리하자면 다음과 같다.
  
  - Prometheus

    오픈 소스 모니터링 시스템 및 시계열 데이터베이스로, istio와 함께 Prometheus를 사용하여 서비스 메시 내에서 **애플리케이션의 상태를 추적하는 메트릭을 기록**한다. Prometheus로 수집된 메트릭은 Grafana 및 Kiali와 같은 도구를 사용하여 시각화 할 수 있다.

  - Grafana

    istio용 대시보드를 구성할 수 있는 오픈 소스 모니터링 도구로, Grafana를 사용하여 서비스 메시 내에서 **애플리케이션의 상태를 모니터링** 할 수 있다.

  - Kiali

    서비스 메시 구성 기능이 있는 istio용 observability 콘솔로, **토폴로지를 유추하여 서비스 메시의 구조를 이해하고 상태를 확인하기 용이**하다. Jaeger를 통합하여 분산 추적을 제공한다.

  - Jaeger

    오픈 소스 종단 간 **분산 추적 시스템**으로, 사용자가 복잡한 복잡한 마이크로서비스 환경을 모니터링하고 문제를 해결하는데 사용한다.

  - Zipkin

    Jaeger와 같은 분산 추적 시스템으로, **Jaeger의 대안이며 기본적으로 배포되지 않는다**.

  <br>

  성공적으로 **istio-system** 네임스페이스가 생기고 모든 리소스가 정상적으로 작동하는 것을 확인하고, ingress 및 egress 트래픽을 제어하기 위해 각 파드에 istio-proxy 컨테이너를 추가할 것이다. 다음 명령을 통해 **default 네임스페이스에 대한 사이드카 삽입을 활성화** 해보겠다.

  ```bash
  son@son-localhost ~ $ kubectl label namespace default istio-injection=enabled --overwrite
  namedefault labeled
  ```

  이제 default 네임스페이스에 배포하는 서비스는 istio-proxy가 사이드카로 같이 올라가기 때문에 트래픽 제어나 보안 등 다양한 istio 의 기능을 사용할 수 있게 된다.

  <br>

### 1.2. helloworld 예제 앱 배포 <a name="list1_2"></a>

  다음은 default 네임스페이스에 샘플 앱인 helloworld를 배포하고 helloworld 서비스(service), 게이트웨이(gateways)와 가상 서비스(virtualservices) 리소스를 생성해보겠다. 해당 매니페스트는 istio 폴더 내의 samples/helloworld 폴더에 helloworld.yaml과 helloworld-gateway.yaml 파일로 존재한다.

  ```bash
  son@son-localhost ~ $ kubectl apply -f istio-1.15.2/samples/helloworld/helloworld.yaml
  service/helloworld created
  son@son-localhost ~ $ kubectl get all
  NAME                                 READY   STATUS    RESTARTS   AGE
  pod/helloworld-v1-78b9f5c87f-tljjx   2/2     Running   0          62s
  pod/helloworld-v2-54dddc5567-sd9td   2/2     Running   0          62s

  NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
  service/helloworld   ClusterIP   10.98.206.190   <none>        5000/TCP   62s
  service/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP    154m

  NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
  deployment.apps/helloworld-v1   1/1     1            1           62s
  deployment.apps/helloworld-v2   1/1     1            1           62s

  NAME                                       DESIRED   CURRENT   READY   AGE
  replicaset.apps/helloworld-v1-78b9f5c87f   1         1         1       62s
  replicaset.apps/helloworld-v2-54dddc5567   1         1         1       62s

  son@son-localhost ~ $ kubectl apply -f istio-1.15.2/samples/helloworld/helloworld-gateway.yaml
  gateway.networking.istio.io/helloworld-gateway created
  virtualservice.networking.istio.io/helloworld created
  son@son-localhost ~ $ kubectl get gateways,virtualservices
  NAME                                             AGE
  gateway.networking.istio.io/helloworld-gateway   30s

  NAME                                            GATEWAYS                 HOSTS   AGE
  virtualservice.networking.istio.io/helloworld   ["helloworld-gateway"]   ["*"]   30s
  ```
  
  혹시나 스크립트로 서버를 관리하거나 작업을 자동화시킨다면 다음 명령어들을 통해 서비스 IP 주소나 포트 번호 등 리소스들의 정보를 가져올 수 있으니 참고바란다. 

  ```bash
  son@son-localhost ~ $ export INGRESS_HOST=$(kubectl get service \
    istio-ingressgateway -n istio-system \
    -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
  son@son-localhost $ echo $INGRESS_HOST
  192.168.49.100

  son@son-localhost ~ $ export INGRESS_PORT=$(kubectl get service \
    istio-ingressgateway -n istio-system \
    -o jsonpath='{.spec.ports[?(@.name=="http2")].port}')
  son@son-localhost ~ $ echo $INGRESS_PORT
  80

  son@son-localhost ~ $ export SECURE_INGRESS_PORT=$(kubectl get service \
    istio-ingressgateway -n istio-system \
    -o jsonpath='{.spec.ports[?(@.name=="https")].port}')
  son@son-localhost ~ $ echo $SECURE_INGRESS_PORT
  443

  son@son-localhost ~ $ export GATEWAY_URL="${INGRESS_HOST}:${INGRESS_PORT}"
  son@son-localhost ~ $ echo $GATEWAY_URL
  192.168.49.100:80

  son@son-localhost ~ $ kubectl get virtualservice helloworld \
    -o jsonpath='{.spec.http[0].match[0].uri}{"\n"}'
  {"exact":"/hello"}
  ```

  위 명령들을 통해 GATEWAY_URL 환경 변수에 helloworld 서비스의 External IP와 port가 조합되어 있을 것 이다. 해당 환경변수를 넣어 curl 명령을 통해 helloworld 서비스가 정상 동작하는지 확인해보겠다. 

  ```bash
  son@son-localhost ~ $ curl -vk# "http://${GATEWAY_URL}/hello"
  *   Trying 192.168.49.100:80...
  * Connected to 192.168.49.100 (192.168.49.100) port 80 (#0)
  > GET /hello HTTP/1.1
  > Host: 192.168.49.100
  > User-Agent: curl/7.81.0
  > Accept: */*
  >
  * Mark bundle as not supporting multiuse
  < HTTP/1.1 200 OK
  < content-type: text/html; charset=utf-8
  < content-length: 60
  < server: istio-envoy
  < date: Thu, 13 Oct 2022 15:24:24 GMT
  < x-envoy-upstream-service-time: 243
  <
  Hello version: v1, instance: helloworld-v1-78b9f5c87f-tljjx
  * Connection #0 to host 192.168.49.100 left intact
  ```

  curl 명령을 통해 http://192.168.49.100:80/hello url로 접근해보니 상태코드 200과 함께 **Hello version: v1, instance: helloworld-v1-78b9f5c87f-tljjx** 이라는 응답이 왔다.

  `kubectl exec -it pod/helloworld-v1-78b9f5c87f-tljjx cat app.py` 명령을 입력하여 helloworld 애플리케이션의 코드를 확인할 수 있는데, /hello 경로로 요청했던 것에 대해 정상적으로 응답받은 것을 확인할 수 있다.

  ```python
  #!/usr/bin/python
  import os, math
  from flask import Flask, request
  app = Flask(__name__)

  @app.route('/hello')
  def hello():
      version = os.environ.get('SERVICE_VERSION')

      # do some cpu intensive computation
      x = 0.0001
      for i in range(0, 1000000):
              x = x + math.sqrt(x)

      return 'Hello version: %s, instance: %s\n' % (version, os.environ.get('HOSTNAME'))

  @app.route('/health')
  def health():
      return 'Helloworld is healthy', 200

  if __name__ == "__main__":
      app.run(host='0.0.0.0', threaded=True)
  ```

  <br>

### 1.3. Kiali dashboard 사용 <a name="list1_3"></a>
  
  kiali dashboard를 사용하기 전에 helloworld 서비스에 트래픽을 발생시키기 위해 새로운 터미널을 열어 loadgen.sh 파일을 실행해보겠다.

  ```bash 
  son@son-localhost ~ $ grep -v '^#' istio-1.15.2/samples/helloworld/loadgen.sh

  while true; do curl -s -o /dev/null "http://$GATEWAY_URL/hello"; done
  son@son-localhost ~ $ ./istio-1.15.2/samples/helloworld/loadgen.sh
  ```

  loadgen.sh에서는 프로세스가 멈출 때까지 **http://$GATEWAY_URL/hello** url에 접근하는데, GATEWAY_URL 환경변수가 설정되어 있지 않다면 위의 내용을 참고하여 설정을 하거나 loadgen.sh 파일 내용을 $GATEWAY_URL 대신 INGRESS_HOST:INGRESS_PORT 형식의 값으로 바꿔넣어주면 된다. 
  
  일정 시간이 지나 프로세스를 멈추려면 **Ctrl + C** 키를 누르면 된다. 다음으로 kiali dashboard를 구동시켜보겠다.
  
  ```bash
  son@son-localhost ~ $ istioctl dashboard kiali
  http://localhost:20001/kiali
  ```

  kiali로 접속할 수 있는 주소가 안내되고, 해당 주소로 접속하면 [그림 1]과 같은 화면을 볼 수 있다.

  | ![kiali-dashboard](/static/assets/img/landing/infra/istio3.png){: width="100%"} |
  |:--:| 
  | [그림 1] kiali dashboard 접속 |

  <br>

  Application 탭에는 istio 수신 게이트웨이, 애플리케이션 서비스 및 요청을 처리하는 파드 간의 연결이 표시된다. Applications를 클릭하고 default 네임스페이스를 선택 후 helloworld 애플리케이션 이름을 클릭하면 다음 [그림 2]와 같이 나올 것이다.

  | ![kiali-applications-overview](/static/assets/img/landing/infra/istio4.png){: width="100%"} |
  |:--:| 
  | [그림 2] kiali Applications Overview 탭 화면 |

  <br>

  Inbound Metrics 탭을 클릭하면 네트워크 트래픽 그래프가 업데이트되면 [그림 3]과 같이 Inbound Metrics가 표시되는 것을 확인할 수 있다.

  | ![kiali-applications-inbound](/static/assets/img/landing/infra/istio5.png){: width="100%"} |
  |:--:| 
  | [그림 3] kiali Applications Inbound Metrics 탭 화면 |

  <br>

  Workloads 탭을 클릭한 다음 배포 이름인 **helloworld-v1**을 클릭한다. Logs 탭을 클릭하면 파드 컨테이너에 대한 로그를 확인할 수 있고, helloworld 애플리케이션 또는 istio-proxy 컨테이너에 대한 로그를 필터링할 수도 있다.

  | ![kiali-workloads-logs](/static/assets/img/landing/infra/istio6.png){: width="100%"} |
  |:--:| 
  | [그림 4] kiali Workloads Logs 탭 화면 |

  <br>

  짧게나마 istio를 사용해보니 모든 컨테이너에 대한 로깅, 메트릭 측정, 정책 등을 통합하여 관리하기 때문에 쿠버네티스의 복잡함을 줄여 효율적으로 관리할 수 있는 것 같다. 대규모 시스템 혹은 대규모 트래픽이 오가는 환경에서 istio를 사용해보고싶은데 언제쯤 해볼 수 있으려나..
  
<br>
